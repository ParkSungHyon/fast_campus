{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['label'] = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['label']\n",
    "X = df.drop(['label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.int64)\n",
    "y_test = torch.tensor(y_test, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.input_layer    = nn.Linear(4, 16)\n",
    "        self.hidden_layer1  = nn.Linear(16, 32)\n",
    "        self.output_layer   = nn.Linear(32, 3)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = self.relu(self.input_layer(x))\n",
    "        out = self.relu(self.hidden_layer1(out))\n",
    "        out = self.output_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(train_loader, model, loss_fn, optimizer):\n",
    "    size = len(train_loader.dataset)\n",
    "    \n",
    "    for batch, (X, y) in enumerate(train_loader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        \n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss, current = loss.item(), batch * len(X)\n",
    "        print(f'loss: {loss}')\n",
    "        print(f'current: {current}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(test_loader, model, loss_fn):\n",
    "    size = len(test_loader.dataset)\n",
    "    num_batches = len(test_loader)\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in test_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f'test_loss: {test_loss}')\n",
    "    print(f'correct: {correct}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "loss: 1.0277338027954102\n",
      "current: 0\n",
      "loss: 1.2351129055023193\n",
      "current: 10\n",
      "loss: 1.2621263265609741\n",
      "current: 20\n",
      "loss: 1.148000955581665\n",
      "current: 30\n",
      "loss: 1.1772562265396118\n",
      "current: 40\n",
      "loss: 1.14656662940979\n",
      "current: 50\n",
      "loss: 1.125928282737732\n",
      "current: 60\n",
      "loss: 1.036603331565857\n",
      "current: 70\n",
      "loss: 1.1560183763504028\n",
      "current: 80\n",
      "loss: 1.0907305479049683\n",
      "current: 90\n",
      "loss: 0.9591138958930969\n",
      "current: 100\n",
      "loss: 1.2175378799438477\n",
      "current: 22\n",
      "test_loss: 1.0744141340255737\n",
      "correct: 0.34210526315789475\n",
      "Epoch 2\n",
      "loss: 1.1707463264465332\n",
      "current: 0\n",
      "loss: 1.0806280374526978\n",
      "current: 10\n",
      "loss: 1.1153770685195923\n",
      "current: 20\n",
      "loss: 0.9962830543518066\n",
      "current: 30\n",
      "loss: 1.0632169246673584\n",
      "current: 40\n",
      "loss: 1.059303879737854\n",
      "current: 50\n",
      "loss: 1.0241563320159912\n",
      "current: 60\n",
      "loss: 1.0463213920593262\n",
      "current: 70\n",
      "loss: 1.0192375183105469\n",
      "current: 80\n",
      "loss: 0.9962997436523438\n",
      "current: 90\n",
      "loss: 1.0191047191619873\n",
      "current: 100\n",
      "loss: 1.082967758178711\n",
      "current: 22\n",
      "test_loss: 1.019709661602974\n",
      "correct: 0.47368421052631576\n",
      "Epoch 3\n",
      "loss: 0.9933908581733704\n",
      "current: 0\n",
      "loss: 0.9999555349349976\n",
      "current: 10\n",
      "loss: 0.9979473948478699\n",
      "current: 20\n",
      "loss: 1.067541480064392\n",
      "current: 30\n",
      "loss: 0.9328503608703613\n",
      "current: 40\n",
      "loss: 0.9801572561264038\n",
      "current: 50\n",
      "loss: 1.0197314023971558\n",
      "current: 60\n",
      "loss: 0.9855300784111023\n",
      "current: 70\n",
      "loss: 1.0023655891418457\n",
      "current: 80\n",
      "loss: 0.9997869729995728\n",
      "current: 90\n",
      "loss: 0.9819279909133911\n",
      "current: 100\n",
      "loss: 1.0037274360656738\n",
      "current: 22\n",
      "test_loss: 0.9761224985122681\n",
      "correct: 0.6578947368421053\n",
      "Epoch 4\n",
      "loss: 0.9294546842575073\n",
      "current: 0\n",
      "loss: 0.986784815788269\n",
      "current: 10\n",
      "loss: 0.8486499786376953\n",
      "current: 20\n",
      "loss: 0.9952999353408813\n",
      "current: 30\n",
      "loss: 0.8680230975151062\n",
      "current: 40\n",
      "loss: 0.9665236473083496\n",
      "current: 50\n",
      "loss: 0.9740725755691528\n",
      "current: 60\n",
      "loss: 0.9182300567626953\n",
      "current: 70\n",
      "loss: 1.0498042106628418\n",
      "current: 80\n",
      "loss: 0.974957287311554\n",
      "current: 90\n",
      "loss: 0.9597959518432617\n",
      "current: 100\n",
      "loss: 0.7718837261199951\n",
      "current: 22\n",
      "test_loss: 0.9239910244941711\n",
      "correct: 0.6578947368421053\n",
      "Epoch 5\n",
      "loss: 0.9090210199356079\n",
      "current: 0\n",
      "loss: 0.9360716938972473\n",
      "current: 10\n",
      "loss: 1.0045793056488037\n",
      "current: 20\n",
      "loss: 0.9854387044906616\n",
      "current: 30\n",
      "loss: 0.8390102386474609\n",
      "current: 40\n",
      "loss: 0.8421341776847839\n",
      "current: 50\n",
      "loss: 0.9046212434768677\n",
      "current: 60\n",
      "loss: 0.8415540456771851\n",
      "current: 70\n",
      "loss: 0.898398756980896\n",
      "current: 80\n",
      "loss: 0.826132595539093\n",
      "current: 90\n",
      "loss: 0.8466911315917969\n",
      "current: 100\n",
      "loss: 0.891622006893158\n",
      "current: 22\n",
      "test_loss: 0.8723519295454025\n",
      "correct: 0.6578947368421053\n",
      "Epoch 6\n",
      "loss: 0.8028463125228882\n",
      "current: 0\n",
      "loss: 0.8466916084289551\n",
      "current: 10\n",
      "loss: 0.8817464709281921\n",
      "current: 20\n",
      "loss: 0.8517190217971802\n",
      "current: 30\n",
      "loss: 1.012219786643982\n",
      "current: 40\n",
      "loss: 0.8083069920539856\n",
      "current: 50\n",
      "loss: 0.8421384692192078\n",
      "current: 60\n",
      "loss: 0.8120962977409363\n",
      "current: 70\n",
      "loss: 0.7682642340660095\n",
      "current: 80\n",
      "loss: 0.815485954284668\n",
      "current: 90\n",
      "loss: 0.7537165284156799\n",
      "current: 100\n",
      "loss: 0.8777100443840027\n",
      "current: 22\n",
      "test_loss: 0.8136971592903137\n",
      "correct: 0.6578947368421053\n",
      "Epoch 7\n",
      "loss: 0.9336298108100891\n",
      "current: 0\n",
      "loss: 0.7887726426124573\n",
      "current: 10\n",
      "loss: 0.7354083061218262\n",
      "current: 20\n",
      "loss: 0.7320572137832642\n",
      "current: 30\n",
      "loss: 0.7871844172477722\n",
      "current: 40\n",
      "loss: 0.8530653119087219\n",
      "current: 50\n",
      "loss: 0.7254483103752136\n",
      "current: 60\n",
      "loss: 0.8639165163040161\n",
      "current: 70\n",
      "loss: 0.6871782541275024\n",
      "current: 80\n",
      "loss: 0.6695411205291748\n",
      "current: 90\n",
      "loss: 0.7441238760948181\n",
      "current: 100\n",
      "loss: 0.8543532490730286\n",
      "current: 22\n",
      "test_loss: 0.7550222277641296\n",
      "correct: 0.6578947368421053\n",
      "Epoch 8\n",
      "loss: 0.7421417832374573\n",
      "current: 0\n",
      "loss: 0.758506178855896\n",
      "current: 10\n",
      "loss: 0.7247814536094666\n",
      "current: 20\n",
      "loss: 0.6923190355300903\n",
      "current: 30\n",
      "loss: 0.8227920532226562\n",
      "current: 40\n",
      "loss: 0.7404672503471375\n",
      "current: 50\n",
      "loss: 0.5906223058700562\n",
      "current: 60\n",
      "loss: 0.7090915441513062\n",
      "current: 70\n",
      "loss: 0.6632659435272217\n",
      "current: 80\n",
      "loss: 0.6571058034896851\n",
      "current: 90\n",
      "loss: 0.7344357967376709\n",
      "current: 100\n",
      "loss: 0.7347968816757202\n",
      "current: 22\n",
      "test_loss: 0.6894377171993256\n",
      "correct: 0.6578947368421053\n",
      "Epoch 9\n",
      "loss: 0.8034520149230957\n",
      "current: 0\n",
      "loss: 0.5760352611541748\n",
      "current: 10\n",
      "loss: 0.6562029123306274\n",
      "current: 20\n",
      "loss: 0.6574889421463013\n",
      "current: 30\n",
      "loss: 0.663591742515564\n",
      "current: 40\n",
      "loss: 0.6935164332389832\n",
      "current: 50\n",
      "loss: 0.6260207891464233\n",
      "current: 60\n",
      "loss: 0.5833438634872437\n",
      "current: 70\n",
      "loss: 0.6886498928070068\n",
      "current: 80\n",
      "loss: 0.7127217650413513\n",
      "current: 90\n",
      "loss: 0.5764672160148621\n",
      "current: 100\n",
      "loss: 0.5014658570289612\n",
      "current: 22\n",
      "test_loss: 0.6381027400493622\n",
      "correct: 0.8157894736842105\n",
      "Epoch 10\n",
      "loss: 0.6813239455223083\n",
      "current: 0\n",
      "loss: 0.6785672903060913\n",
      "current: 10\n",
      "loss: 0.6760766506195068\n",
      "current: 20\n",
      "loss: 0.4968186914920807\n",
      "current: 30\n",
      "loss: 0.6235413551330566\n",
      "current: 40\n",
      "loss: 0.580964982509613\n",
      "current: 50\n",
      "loss: 0.56076979637146\n",
      "current: 60\n",
      "loss: 0.5047611594200134\n",
      "current: 70\n",
      "loss: 0.6287299394607544\n",
      "current: 80\n",
      "loss: 0.6441196203231812\n",
      "current: 90\n",
      "loss: 0.5511327385902405\n",
      "current: 100\n",
      "loss: 0.31822293996810913\n",
      "current: 22\n",
      "test_loss: 0.5843955278396606\n",
      "correct: 0.6578947368421053\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for i in range(epochs):\n",
    "    print(f\"Epoch {i+1}\")\n",
    "    train_loop(train_dataloader,  model, loss, optimizer)\n",
    "    test_loop(test_dataloader, model, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
